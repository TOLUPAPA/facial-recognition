{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths =list(paths.list_images('Images'))\n",
    "image_paths\n",
    "known_names = []\n",
    "known_encodings = []\n",
    "# print(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in image_paths:\n",
    "    name = image.split('\\\\')[1]\n",
    "    bgr_img = cv2.imread(image)\n",
    "    #print(bgr_img)\n",
    "    rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = face_recognition.face_locations (rgb_img, model = 'hog')\n",
    "    encodings = face_recognition.face_encodings(rgb_img, faces)\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        known_names.append(name)\n",
    "        known_encodings.append(encoding)\n",
    "        \n",
    "data = {'names' : known_names, 'encodings' : known_encodings}\n",
    "\n",
    "with open('face_encodings', 'wb') as f:\n",
    "    f.write(pickle.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = cv2.imread('group (2).jpg')\n",
    "new_image = cv2.resize(new_image, None, fx = 0.25, fy = 0.25)\n",
    "rgb_new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces = face_recognition.face_locations(new_image,)\n",
    "\n",
    "encodings = face_recognition.face_encodings(rgb_new_image, faces)\n",
    "\n",
    "with open ('face_encodings', 'rb') as f:\n",
    "    data = pickle.loads(f.read())\n",
    "\n",
    "count_names = {}\n",
    "names = []\n",
    "for encoding in encodings:\n",
    "    #matches = face_recognition.compare_faces(data['encodings'] , encoding)\n",
    "    distances = face_recognition.face_distance(data['encodings'] , encoding)\n",
    "    min_value = np.min(distances)\n",
    "    if min_value > 0.3:\n",
    "        name = 'Unknown'\n",
    "    else:\n",
    "        i = np.argmin(distances)\n",
    "        name = data['names'][i]\n",
    "    names.append(name)\n",
    "    \n",
    "    \n",
    "   # if True in matches:\n",
    "    #    match_idx = [i for i, match in enumerate(matches) if match]\n",
    "     #  \n",
    "      #  for i in match_idx:\n",
    "       #     name = data['names'][i]\n",
    "        #    count_names[name] = count_names.get(name, 0) + 1\n",
    "        #name = max(count_names, key = count_names.get)\n",
    "    #names.append(name)\n",
    "    \n",
    "print(names)\n",
    "face_names = list(zip(faces, names))\n",
    "for ((top,right,bottom,left), name) in face_names:\n",
    "    cv2.rectangle(new_image, (left,top), (right, bottom), (255,0,0), 4)\n",
    "    cv2.putText(new_image,name, (left-2, top-5), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,255,0), 2 )\n",
    "    \n",
    "cv2.imshow('Picture', new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "with open ('face_encodings', 'rb') as f:\n",
    "    data = pickle.loads(f.read())\n",
    "count_names = {}\n",
    "names = []\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    rgb_frame= cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_recognition.face_locations(frame)\n",
    "    encodings = face_recognition.face_encodings(rgb_frame, faces)\n",
    "\n",
    "\n",
    "\n",
    "    for encoding in encodings:\n",
    "        matches = face_recognition.compare_faces(data['encodings'] , encoding)\n",
    "        min_value = np.min(distances)\n",
    "        if min_value > 0.3:\n",
    "            name = 'Unknown'\n",
    "        else:\n",
    "            i = np.argmin(distances)\n",
    "            name = data['names'][i]\n",
    "        names.append(name)\n",
    "            \n",
    "    \n",
    "        #if True in matches:\n",
    "           # match_idx = [i for i, match in enumerate(matches) if match]\n",
    "       \n",
    "            #for i in match_idx:\n",
    "                #name = data['names'][i]\n",
    "               # count_names[name] = count_names.get(name, 0) + 1\n",
    "            #name = max(count_names, key = count_names.get)\n",
    "        #names.append(name)\n",
    "    face_names = list(zip(faces, names))\n",
    "    for ((top,right,bottom,left), name) in face_names:\n",
    "        cv2.rectangle(frame, (left,top), (right, bottom), (255,0,0), 4)\n",
    "        cv2.putText(frame,name, (left-2, bottom-5), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,255,0), 2 )\n",
    "    cv2.imshow('face', frame)\n",
    "    key = cv2.waitKey(100)\n",
    "    if key ==ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
